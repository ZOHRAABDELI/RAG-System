import os
from dotenv import load_dotenv
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

load_dotenv()

# --- API Configuration ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ---  Model Configuration ---
LLM_MODEL_NAME = "models/gemini-2.0-flash"  

#  Embedding Model - BGE-M3 with optimized settings
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"
EMBEDDING_MODEL = HuggingFaceEmbedding(
    model_name=EMBEDDING_MODEL_NAME,
    max_length=512,  
    normalize=True   # Normalize embeddings for better similarity
)

# Alternative embedding models for specific use cases
EMBEDDING_MODELS = {
    "multilingual": "BAAI/bge-m3",
    "english": "BAAI/bge-large-en-v1.5", 
    "arabic": "aubmindlab/bert-base-arabertv02",
    "legal": "nlpaueb/legal-bert-base-uncased"
}

# --- Enhanced Vector Store Configuration ---
VECTORSTORE_DIR = "./chroma_db"
CHROMA_COLLECTION_NAME = "enhanced_legal_documents"

# Language-specific and domain-specific collections
CHROMA_COLLECTIONS = {
    "arabic": "legal_documents_ar_v2",
    "english": "legal_documents_en_v2",
    "other": "legal_documents_other_v2",
    "unified": "legal_documents_unified_v2",
    "contracts": "legal_contracts",
    "regulations": "legal_regulations",
    "policies": "legal_policies"
}

# ---  Document Processing Configuration ---
# Optimized chunking parameters 
CHUNK_SIZE = 1200           
CHUNK_OVERLAP = 400        
MIN_CHUNK_SIZE = 100      
MAX_CHUNK_SIZE = 2000   

# Semantic chunking parameters
SEMANTIC_SIMILARITY_THRESHOLD = 0.8
SEMANTIC_BUFFER_SIZE = 2

# ---  Retrieval Configuration ---
# Optimized retrieval parameters
DEFAULT_SIMILARITY_TOP_K = 50    
VECTOR_TOP_K = 70             
KEYWORD_TOP_K = 50              
FINAL_TOP_K = 30                

# Similarity thresholds
SIMILARITY_THRESHOLD = 0.5       # Minimum similarity for inclusion
HIGH_CONFIDENCE_THRESHOLD = 0.8  # High confidence threshold
LOW_CONFIDENCE_THRESHOLD = 0.3   # Low confidence threshold

# ---  Reranking Configuration ---
RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"
RERANKER_MODELS = {
    "fast": "cross-encoder/ms-marco-TinyBERT-L-2-v2",
    "balanced": "cross-encoder/ms-marco-MiniLM-L-6-v2", 
    "high_quality": "cross-encoder/ms-marco-electra-base"
}

# Reranking parameters
RERANK_TOP_N = 20               # Number of results to rerank
RERANK_BATCH_SIZE = 32          # Batch size for reranking
RERANK_SCORE_THRESHOLD = 0.1    # Minimum rerank score

# --- Language Detection Configuration ---
ARABIC_THRESHOLD = 0.25         # Lowered for better detection
MIN_TEXT_LENGTH = 5             # Minimum text length for detection
LANGUAGE_CONFIDENCE_THRESHOLD = 0.8

# Enhanced language patterns
ARABIC_SCRIPT_RANGES = [
    (0x0600, 0x06FF),  # Arabic
    (0x0750, 0x077F),  # Arabic Supplement
    (0x08A0, 0x08FF),  # Arabic Extended-A
    (0xFB50, 0xFDFF),  # Arabic Presentation Forms-A
    (0xFE70, 0xFEFF),  # Arabic Presentation Forms-B
]

# --- Enhanced Legal Patterns ---
ARABIC_LEGAL_PATTERNS = {
    'articles': [
        r'ÿßŸÑŸÖÿßÿØÿ©\s+\d+',
        r'ÿßŸÑŸÖÿßÿØÿ©\s+ÿ±ŸÇŸÖ\s+\d+', 
        r'ŸÖ\.\s*\d+',
        r'ŸÖÿßÿØÿ©\s+\d+',
        r'ÿßŸÑŸÅÿµŸÑ\s+\d+'
    ],
    'paragraphs': [
        r'ÿßŸÑŸÅŸÇÿ±ÿ©\s+\d+',
        r'ŸÅŸÇÿ±ÿ©\s+\d+', 
        r'ŸÅ\.\s*\d+',
        r'ÿßŸÑÿ®ŸÜÿØ\s+\d+'
    ],
    'sections': [
        r'ÿßŸÑŸÇÿ≥ŸÖ\s+\d+',
        r'ÿßŸÑÿ®ÿßÿ®\s+\d+', 
        r'ŸÇ\.\s*\d+',
        r'ÿßŸÑÿ¨ÿ≤ÿ°\s+\d+'
    ],
    'chapters': [
        r'ÿßŸÑÿ®ÿßÿ®\s+\d+',
        r'ÿßŸÑŸÅÿµŸÑ\s+\d+', 
        r'ÿ®\.\s*\d+',
        r'ÿßŸÑŸÉÿ™ÿßÿ®\s+\d+'
    ],
    'clauses': [
        r'ÿßŸÑÿ®ŸÜÿØ\s+\d+',
        r'ÿßŸÑÿ¥ÿ±ÿ∑\s+\d+',
        r'ÿßŸÑŸÜŸÇÿ∑ÿ©\s+\d+'
    ]
}

ENGLISH_LEGAL_PATTERNS = {
    'articles': [
        r'Article\s+\d+',
        r'Art\.\s*\d+', 
        r'A\.\s*\d+',
        r'Section\s+\d+',
        r'¬ß\s*\d+'
    ],
    'paragraphs': [
        r'Paragraph\s+\d+',
        r'Para\.\s*\d+', 
        r'P\.\s*\d+',
        r'\(\d+\)',
        r'Subsection\s+\d+'
    ],
    'sections': [
        r'Section\s+\d+',
        r'Sec\.\s*\d+', 
        r'S\.\s*\d+',
        r'Part\s+\d+'
    ],
    'chapters': [
        r'Chapter\s+\d+',
        r'Ch\.\s*\d+', 
        r'C\.\s*\d+',
        r'Title\s+\d+'
    ],
    'clauses': [
        r'Clause\s+\d+',
        r'Cl\.\s*\d+',
        r'Item\s+\d+',
        r'Point\s+\d+'
    ]
}

# --- Enhanced Response Templates ---
ARABIC_RESPONSE_TEMPLATE = """
**ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÖŸÅÿµŸÑÿ©:**
{response_content}

**ÿßŸÑŸÖÿµÿßÿØÿ± ŸàÿßŸÑŸÖÿ±ÿßÿ¨ÿπ:**
{sources}

**ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ•ÿ∂ÿßŸÅŸäÿ©:**
- ÿπÿØÿØ ÿßŸÑŸÖÿµÿßÿØÿ± ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿ©: {num_sources}
- ŸÖÿ≥ÿ™ŸàŸâ ÿßŸÑÿ´ŸÇÿ©: {confidence_level}
- ÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿ®ÿ≠ÿ´: {search_method}
"""

ENGLISH_RESPONSE_TEMPLATE = """
**Detailed Answer:**
{response_content}

**Sources and References:**
{sources}

**Additional Information:**
- Number of sources used: {num_sources}
- Confidence level: {confidence_level}
- Search method: {search_method}
"""

# --- Security and Validation Configuration ---
MAX_QUERY_LENGTH = 3000          # Increased for complex queries
MAX_RESPONSE_LENGTH = 8000       # Maximum response length
ALLOWED_FILE_TYPES = ['.pdf', '.docx', '.txt', '.md']
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB per file
MAX_TOTAL_SIZE = 500 * 1024 * 1024  # 500MB total

# Enhanced security patterns
SUSPICIOUS_PATTERNS = [
    r'<script[^>]*>.*?</script>',
    r'javascript\s*:',
    r'data\s*:\s*text/html',
    r'eval\s*\(',
    r'exec\s*\(',
    r'<iframe[^>]*>',
    r'on\w+\s*=',
    r'document\.',
    r'window\.',
    r'\.innerHTML',
    r'\.outerHTML'
]

# Content validation patterns
VALID_QUERY_PATTERNS = [
    r'what|who|where|when|why|how',  # Question words
    r'list|show|explain|define|describe',  # Action words
    r'[\u0600-\u06FF]+',  # Arabic text
    r'[a-zA-Z]+',  # English text
]

# --- Advanced Logging Configuration ---
LOG_LEVEL = "INFO"
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"
LOG_FILE = "enhanced_rag_agent.log"
LOG_MAX_SIZE = 10 * 1024 * 1024  # 10MB
LOG_BACKUP_COUNT = 5

# --- Performance Configuration ---
ENABLE_CACHING = True
CACHE_SIZE = 1000
CACHE_TTL = 3600  # 1 hour

# Processing timeouts
DOCUMENT_PROCESSING_TIMEOUT = 300  # 5 minutes
QUERY_PROCESSING_TIMEOUT = 60      # 1 minute
EMBEDDING_TIMEOUT = 120            # 2 minutes

# --- Feature Flags ---
ENABLE_RERANKING = True
ENABLE_LANGUAGE_SEPARATION = True
ENABLE_HYBRID_SEARCH = True
ENABLE_SEMANTIC_CHUNKING = True
ENABLE_RESPONSE_VERIFICATION = True
ENABLE_METADATA_ENHANCEMENT = True
ENABLE_QUERY_OPTIMIZATION = True

# Advanced features
ENABLE_QUERY_EXPANSION = False      # Experimental
ENABLE_ANSWER_FUSION = False        # Experimental
ENABLE_FACT_CHECKING = False        # Experimental

# --- UI Configuration ---
PAGE_CONFIG = {
    "page_title": "ü§ñ  Agentic RAG System",
    "page_icon": "‚öñÔ∏è",
    "layout": "wide",
    "initial_sidebar_state": "expanded"
}

STREAMLIT_THEME = {
    "primaryColor": "#1f77b4",
    "backgroundColor": "#ffffff",
    "secondaryBackgroundColor": "#f0f2f6",
    "textColor": "#262730",
    "font": "sans serif"
}

# Chart and visualization settings
CHART_COLORS = {
    "primary": "#1f77b4",
    "secondary": "#ff7f0e", 
    "success": "#2ca02c",
    "warning": "#ff9800",
    "error": "#d62728"
}

# ---  Error Messages ---
ERROR_MESSAGES = {
    "arabic": {
        "no_documents": "ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿπÿ´Ÿàÿ± ÿπŸÑŸâ Ÿàÿ´ÿßÿ¶ŸÇ. Ÿäÿ±ÿ¨Ÿâ ÿ±ŸÅÿπ ŸÖŸÑŸÅÿßÿ™ PDF ÿ£ŸàŸÑÿßŸã.",
        "processing_error": "ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ.",
        "query_error": "ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿπÿßŸÑÿ¨ÿ© ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ŸÉ.",
        "invalid_input": "ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ± ÿ∫Ÿäÿ± ÿµÿßŸÑÿ≠. Ÿäÿ±ÿ¨Ÿâ ÿ•ÿπÿßÿØÿ© ÿµŸäÿßÿ∫ÿ© ÿßŸÑÿ≥ÿ§ÿßŸÑ.",
        "no_answer": "ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ•ÿ¨ÿßÿ®ÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖŸÇÿØŸÖÿ©.",
        "llm_config_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ŸÉŸàŸäŸÜ LLM. ÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ŸÖŸÅÿ™ÿßÿ≠ API ŸàÿßŸÑŸÜŸÇÿ∑ÿ© ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ©.",
        "llama_parse_key_missing": "ŸÖŸÅÿ™ÿßÿ≠ API ÿßŸÑÿÆÿßÿµ ÿ®ŸÄ LlamaParse ŸÖŸÅŸÇŸàÿØ. Ÿäÿ±ÿ¨Ÿâ ÿ•ÿ∂ÿßŸÅÿ™Ÿá ÿ•ŸÑŸâ ŸÖŸÑŸÅ .env.",
        "embedding_error": "ÿÆÿ∑ÿ£ ŸÅŸä ŸÜŸÖŸàÿ∞ÿ¨ ÿßŸÑÿ™ÿ∂ŸÖŸäŸÜ. ÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑÿ™ŸÉŸàŸäŸÜ.",
        "retrieval_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ŸàÿßŸÑÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπ.",
        "reranking_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿπŸÖŸÑŸäÿ© ÿ•ÿπÿßÿØÿ© ÿßŸÑÿ™ÿ±ÿ™Ÿäÿ®.",
        "timeout_error": "ÿßŸÜÿ™Ÿáÿ™ ŸÖŸáŸÑÿ© ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.",
        "file_too_large": "ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ ŸÉÿ®Ÿäÿ± ÿ¨ÿØÿßŸã. ÿßŸÑÿ≠ÿØ ÿßŸÑÿ£ŸÇÿµŸâ ÿßŸÑŸÖÿ≥ŸÖŸàÿ≠: {max_size}MB.",
        "unsupported_format": "ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑŸÖŸÑŸÅ ÿ∫Ÿäÿ± ŸÖÿØÿπŸàŸÖ. ÿßŸÑÿ£ŸÜŸàÿßÿπ ÿßŸÑŸÖÿØÿπŸàŸÖÿ©: {formats}.",
        "metadata_extraction_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸàÿµŸÅŸäÿ©.",
        "language_detection_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÑÿ∫ÿ©.",
        "chunking_error": "ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÜÿµ ÿ•ŸÑŸâ ÿ£ÿ¨ÿ≤ÿßÿ°.",
        "indexing_error": "ÿÆÿ∑ÿ£ ŸÅŸä ŸÅŸáÿ±ÿ≥ÿ© ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ.",
        "verification_failed": "ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿ¨ŸàÿØÿ© ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ©."
    },
    "english": {
        "no_documents": "No documents found. Please upload files first.",
        "processing_error": "Error occurred while processing documents.",
        "query_error": "Error occurred while processing your query.",
        "invalid_input": "Invalid query. Please rephrase your question.",
        "no_answer": "No answer found in the provided documents.",
        "llm_config_error": "LLM configuration error. Check API key and endpoint.",
        "llama_parse_key_missing": "LlamaParse API key missing. Please add it to your .env file.",
        "embedding_error": "Embedding model error. Check configuration.",
        "retrieval_error": "Error in search and retrieval process.",
        "reranking_error": "Error in reranking process.",
        "timeout_error": "Processing timeout. Please try again.",
        "file_too_large": "File too large. Maximum allowed size: {max_size}MB.",
        "unsupported_format": "Unsupported file format. Supported types: {formats}.",
        "metadata_extraction_error": "Error extracting metadata.",
        "language_detection_error": "Error detecting language.",
        "chunking_error": "Error chunking text.",
        "indexing_error": "Error indexing documents.",
        "verification_failed": "Response quality verification failed."
    }
}

# ---  Success Messages ---
SUCCESS_MESSAGES = {
    "arabic": {
        "documents_processed": "ÿ™ŸÖ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿ®ŸÜÿ¨ÿßÿ≠!",
        "index_built": "ÿ™ŸÖ ÿ®ŸÜÿßÿ° ÿßŸÑŸÅŸáÿ±ÿ≥ ÿ®ŸÜÿ¨ÿßÿ≠!",
        "data_cleared": "ÿ™ŸÖ ŸÖÿ≥ÿ≠ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ®ŸÜÿ¨ÿßÿ≠.",
        "embedding_complete": "ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿ™ÿ∂ŸÖŸäŸÜÿßÿ™ ÿ®ŸÜÿ¨ÿßÿ≠.",
        "retrieval_complete": "ÿ™ŸÖ ÿßŸÑÿ®ÿ≠ÿ´ ŸàÿßŸÑÿßÿ≥ÿ™ÿ±ÿ¨ÿßÿπ ÿ®ŸÜÿ¨ÿßÿ≠.",
        "reranking_complete": "ÿ™ŸÖ ÿ•ÿπÿßÿØÿ© ÿßŸÑÿ™ÿ±ÿ™Ÿäÿ® ÿ®ŸÜÿ¨ÿßÿ≠.",
        "response_generated": "ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿ®ŸÜÿ¨ÿßÿ≠.",
        "metadata_extracted": "ÿ™ŸÖ ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿßŸÑŸàÿµŸÅŸäÿ© ÿ®ŸÜÿ¨ÿßÿ≠.",
        "language_detected": "ÿ™ŸÖ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÑÿ∫ÿ© ÿ®ŸÜÿ¨ÿßÿ≠.",
        "chunks_created": "ÿ™ŸÖ ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÜÿµ ÿ®ŸÜÿ¨ÿßÿ≠.",
        "verification_passed": "ÿ™ŸÖ ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿ¨ŸàÿØÿ© ÿßŸÑÿßÿ≥ÿ™ÿ¨ÿßÿ®ÿ© ÿ®ŸÜÿ¨ÿßÿ≠."
    },
    "english": {
        "documents_processed": "Documents processed successfully!",
        "index_built": "Index built successfully!",
        "data_cleared": "Data cleared successfully.",
        "embedding_complete": "Embeddings created successfully.",
        "retrieval_complete": "Search and retrieval completed successfully.",
        "reranking_complete": "Reranking completed successfully.",
        "response_generated": "Response generated successfully.",
        "metadata_extracted": "Metadata extracted successfully.",
        "language_detected": "Language detected successfully.",
        "chunks_created": "Text chunking completed successfully.",
        "verification_passed": "Response quality verification passed."
    }
}

# ---  Prompt Templates ---
SYSTEM_PROMPTS = {
    "arabic": {
        "comprehensive": """ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ. ÿßÿ™ÿ®ÿπ Ÿáÿ∞Ÿá ÿßŸÑÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿ®ÿØŸÇÿ©:

1. **ÿßŸÑÿßÿπÿ™ŸÖÿßÿØ ÿßŸÑŸÉÿßŸÖŸÑ**: ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖŸÇÿØŸÖÿ©ÿå ŸàŸÑÿß ÿ™ÿ∂ŸÅ ÿ£Ÿä ŸÖÿπÿ±ŸÅÿ© ŸÖŸÜ ÿÆÿßÿ±ÿ¨Ÿáÿß.
2. **ÿßŸÑÿØŸÇÿ©**: ÿßŸÇÿ™ÿ®ÿ≥ ÿßŸÑŸÜÿµŸàÿµ ÿ£Ÿà ÿßŸÑŸÖŸÇÿßÿ∑ÿπ ŸÉŸÖÿß Ÿàÿ±ÿØÿ™ ŸÖÿπ ÿßŸÑÿ•ÿ¥ÿßÿ±ÿ© ÿ•ŸÑŸâ ÿ£ÿ±ŸÇÿßŸÖ ÿßŸÑÿµŸÅÿ≠ÿßÿ™ ÿ£Ÿà ÿßŸÑÿπŸÜÿßŸàŸäŸÜ ÿπŸÜÿØ ÿ™ŸàŸÅÿ±Ÿáÿß.
3. **ÿßŸÑÿ¥ŸÖŸàŸÑŸäÿ©**: ÿßÿ®ÿ≠ÿ´ ŸÅŸä ŸÉÿßŸÖŸÑ ÿßŸÑÿ≥ŸäÿßŸÇ ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©.
4. **ÿßŸÑŸàÿ∂Ÿàÿ≠ ŸàÿßŸÑÿ™ŸÜÿ∏ŸäŸÖ**: ŸÇÿØŸÖ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ŸÅŸä ÿ¥ŸÉŸÑ ŸÜŸÇÿßÿ∑ ÿ£Ÿà ŸÅŸÇÿ±ÿßÿ™ ŸÖÿ±ŸÇŸÖÿ©.
5. **ÿßŸÑÿ™ÿ≠ŸÇŸÇ**: ÿ™ÿ£ŸÉÿØ ÿ£ŸÜ ŸÉŸÑ ŸÖÿπŸÑŸàŸÖÿ© ŸÖÿØÿπŸàŸÖÿ© ÿ®ÿßŸÑŸàÿ´ŸäŸÇÿ©.
6. **ÿßŸÑŸÜŸÇÿµ ŸÅŸä ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™**: ÿ•ÿ∞ÿß ŸÑŸÖ ÿ™ÿ¨ÿØ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉÿßŸÅŸäÿ©ÿå ÿ£ÿ¨ÿ® ÿ®Ÿàÿ∂Ÿàÿ≠: "ŸÑÿß ÿ™Ÿàÿ¨ÿØ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉÿßŸÅŸäÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ ÿßŸÑŸÖŸÇÿØŸÖÿ©".

ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÖÿ™ŸàŸÇÿπÿ©:
- ÿßŸÑŸÜŸÇÿ∑ÿ© ÿßŸÑÿ£ŸàŸÑŸâ (ÿßŸÑÿµŸÅÿ≠ÿ©/ÿßŸÑÿπŸÜŸàÿßŸÜ)
- ÿßŸÑŸÜŸÇÿ∑ÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ© (ÿßŸÑÿµŸÅÿ≠ÿ©/ÿßŸÑÿπŸÜŸàÿßŸÜ)
...""",

        "list_extraction": """ÿ£ŸÜÿ™ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑŸÇŸàÿßÿ¶ŸÖ ŸÖŸÜ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ. ÿπŸÜÿØ ÿ∑ŸÑÿ® ŸÇÿßÿ¶ŸÖÿ©:

1. **ÿßÿ¨ŸÖÿπ ŸÉŸÑ ÿßŸÑÿπŸÜÿßÿµÿ±** ŸÉŸÖÿß Ÿàÿ±ÿØÿ™ ÿØŸàŸÜ ÿ™ÿπÿØŸäŸÑ.
2. **ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿßŸÑÿ™ÿ±ŸÇŸäŸÖ ÿ£Ÿà ÿßŸÑÿ™ÿ±ÿ™Ÿäÿ® ÿßŸÑÿ£ÿµŸÑŸä** ÿ•ŸÜ ŸàŸèÿ¨ÿØ.
3. **ÿßÿ∞ŸÉÿ± ÿßŸÑŸÖÿµÿØÿ±** (ÿµŸÅÿ≠ÿ©/ÿπŸÜŸàÿßŸÜ/ŸÅŸÇÿ±ÿ©) ŸÖÿπ ŸÉŸÑ ÿπŸÜÿµÿ±.
4. **ÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿßŸÑÿßŸÉÿ™ŸÖÿßŸÑ**: ŸÑÿß ÿ™ÿ≥ŸÇÿ∑ ÿ£Ÿä ÿπŸÜÿµÿ±.
5. **ÿßŸÑÿ™ÿ≤ŸÖ ÿ®ÿßŸÑÿ£ÿµŸÑ**: ŸÑÿß ÿ™ÿ∂ŸÅ ÿ£Ÿà ÿ™ÿ≠ÿ∞ŸÅ ÿ£Ÿä ÿ¥Ÿäÿ°.

ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©:
- ÿßŸÑÿπŸÜÿµÿ± ÿßŸÑÿ£ŸàŸÑ (ÿßŸÑÿµŸÅÿ≠ÿ©/ÿßŸÑÿπŸÜŸàÿßŸÜ)
- ÿßŸÑÿπŸÜÿµÿ± ÿßŸÑÿ´ÿßŸÜŸä (ÿßŸÑÿµŸÅÿ≠ÿ©/ÿßŸÑÿπŸÜŸàÿßŸÜ)
...""",

        "explanation": """ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿ¥ÿ±ÿ≠ ÿßŸÑŸÖŸÅÿßŸáŸäŸÖ ÿßŸÑŸàÿßÿ±ÿØÿ© ŸÅŸä ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ. ÿπŸÜÿØ ÿßŸÑÿ¥ÿ±ÿ≠:

1. **ÿßÿ®ÿØÿ£ ÿ®ÿßŸÑÿ™ÿπÿ±ŸäŸÅ ÿ£Ÿà ÿßŸÑŸÜÿµ ÿßŸÑÿ£ÿµŸÑŸä** ŸÉŸÖÿß Ÿàÿ±ÿØ ŸÅŸä ÿßŸÑŸàÿ´ŸäŸÇÿ©.
2. **ÿ£ÿ∂ŸÅ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ®ÿßÿ¥ÿ±** ŸÖŸÜ ÿßŸÑŸàÿ´ÿßÿ¶ŸÇ.
3. **ÿßÿ±ÿ®ÿ∑ ÿ®ÿßŸÑÿ£ÿ¨ÿ≤ÿßÿ° ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©** ÿπŸÜÿØ ÿßŸÑÿ•ŸÖŸÉÿßŸÜ.
4. **ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÖÿµÿ∑ŸÑÿ≠ÿßÿ™ ÿßŸÑÿ£ÿµŸÑŸäÿ©** ŸÉŸÖÿß ŸáŸä ÿØŸàŸÜ ÿ™ÿ∫ŸäŸäÿ±.
5. **ÿ™ÿ¨ŸÜÿ® ÿ£Ÿä ÿ™ŸÅÿ≥Ÿäÿ± ÿ¥ÿÆÿµŸä** ÿ£Ÿà ÿ•ÿ∂ÿßŸÅÿ© ÿÆÿßÿ±ÿ¨Ÿäÿ©.

ÿ™ŸÜÿ≥ŸäŸÇ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ©:
- ÿßŸÑÿ™ÿπÿ±ŸäŸÅ
- ÿßŸÑÿ≥ŸäÿßŸÇ
- ÿßŸÑÿ£ÿ¨ÿ≤ÿßÿ° ÿ∞ÿßÿ™ ÿßŸÑÿµŸÑÿ©"""
    },

    "english": {
        "comprehensive": """You are an AI assistant specialized in analyzing documents. Follow these rules strictly:

1. **Exclusive reliance**: Use only information found in the provided documents; do not add external knowledge.
2. **Accuracy**: Quote passages exactly as written and include page numbers, headings, or references when available.
3. **Completeness**: Search across the entire context to capture all relevant information.
4. **Clarity & structure**: Present answers as bullet points or clearly numbered sections.
5. **Verification**: Ensure every statement is supported by the document.
6. **Insufficient info**: If enough information is not available, clearly state: "Insufficient information in provided documents."

Expected answer format:
- First point (page/heading)
- Second point (page/heading)
...""",

        "list_extraction": """You are specialized in extracting lists from documents. When a list is requested:

1. **Gather all elements** exactly as they appear in the text.
2. **Preserve numbering or order** if present.
3. **Cite the source** (page/heading/paragraph) for each item.
4. **Ensure completeness**: do not skip any item.
5. **Stay faithful**: do not add or remove content.

Response format:
- First element (page/heading)
- Second element (page/heading)
...""",

        "explanation": """You are an assistant specialized in explaining concepts found in documents. When explaining:

1. **Start with the definition or original statement** as it appears in the document.
2. **Add direct context** from the surrounding content.
3. **Link to related sections** if available.
4. **Use the original terminology** exactly as given.
5. **Avoid personal interpretation** or external additions.

Expected answer structure:
- Definition
- Context
- Related sections"""
    }
}


# --- Quality Assurance Configuration ---
QUALITY_METRICS = {
    "response_length_min": 20,
    "response_length_max": 5000,
    "citation_requirement": True,
    "source_verification": True,
    "language_consistency": True,
    "factual_accuracy": True
}

# Response quality thresholds
QUALITY_THRESHOLDS = {
    "excellent": 0.9,
    "good": 0.7,
    "acceptable": 0.5,
    "poor": 0.3
}

# ---  Retrieval Strategies ---
RETRIEVAL_STRATEGIES = {
    "precision": {
        "vector_top_k": 20,
        "keyword_top_k": 10,
        "final_top_k": 8,
        "similarity_threshold": 0.7,
        "alpha": 0.8  # Favor vector search
    },
    "recall": {
        "vector_top_k": 50,
        "keyword_top_k": 25,
        "final_top_k": 20,
        "similarity_threshold": 0.4,
        "alpha": 0.6  # Balanced approach
    },
    "balanced": {
        "vector_top_k": 30,
        "keyword_top_k": 15,
        "final_top_k": 12,
        "similarity_threshold": 0.5,
        "alpha": 0.7  # Slight favor to vector
    }
}

# --- Document Type Specific Configuration ---
DOCUMENT_TYPES = {
    "law": {
        "chunking_strategy": "semantic",
        "chunk_size": 1500,
        "overlap": 500,
        "embedding_model": "legal"
    },
    "contract": {
        "chunking_strategy": "sentence",
        "chunk_size": 1000,
        "overlap": 300,
        "embedding_model": "multilingual"
    },
    "regulation": {
        "chunking_strategy": "fixed",
        "chunk_size": 1200,
        "overlap": 400,
        "embedding_model": "multilingual"
    },
    "policy": {
        "chunking_strategy": "semantic",
        "chunk_size": 800,
        "overlap": 200,
        "embedding_model": "multilingual"
    }
}

# --- Monitoring and Analytics ---
MONITORING_CONFIG = {
    "track_queries": True,
    "track_responses": True,
    "track_performance": True,
    "track_errors": True,
    "analytics_retention_days": 30
}

# Performance benchmarks
PERFORMANCE_BENCHMARKS = {
    "document_processing_time": 60,  # seconds per MB
    "query_response_time": 10,       # seconds
    "embedding_time": 5,             # seconds per chunk
    "retrieval_time": 3              # seconds
}

# --- Export Configuration ---
EXPORT_FORMATS = {
    "json": True,
    "csv": True,
    "pdf": False,  # Requires additional dependencies
    "xlsx": True
}

# --- Development and Debug Configuration ---
DEBUG_MODE = os.getenv("DEBUG_MODE", "False").lower() == "true"
VERBOSE_LOGGING = os.getenv("VERBOSE_LOGGING", "False").lower() == "true"
PROFILING_ENABLED = os.getenv("PROFILING_ENABLED", "False").lower() == "true"

# Debug settings
if DEBUG_MODE:
    LOG_LEVEL = "DEBUG"
    CHUNK_SIZE = 800 
    VECTOR_TOP_K = 20  

# --- Version and Compatibility ---
RAG_SYSTEM_VERSION = "2.0.0"
SUPPORTED_LLAMAINDEX_VERSION = ">=0.10.0"
SUPPORTED_PYTHON_VERSION = ">=3.8"

# ---  Configuration ---
BEST_PRACTICES = {
    "chunk_overlap_ratio": 0.3,  
    "max_chunks_per_doc": 1000,
    "min_chunk_chars": 100,
    "max_chunk_chars": 2000,
    "rerank_threshold": 0.1,
    "response_verification": True,
    "metadata_enrichment": True,
    "query_preprocessing": True,
    "response_postprocessing": True
}
